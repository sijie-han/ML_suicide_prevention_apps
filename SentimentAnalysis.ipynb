{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = pd.read_csv('Final.csv').reset_index(drop=False)[['index','cleaned_text','label']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_data['cleaned_text'].values, X_data['label'].values, test_size=0.2, random_state=142, shuffle=True, stratify=X_data['label'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_extractor(corpus, min_df, encoding, ngram_range=(1,2), max_df=1.0):\n",
    "    vectorizer = TfidfVectorizer(preprocessor=None, lowercase=False, min_df=min_df, max_df=max_df, \n",
    "                                 norm='l2', smooth_idf=True, use_idf=True, ngram_range=ngram_range, encoding=encoding, \n",
    "                                 sublinear_tf=True)\n",
    "    features = vectorizer.fit_transform(corpus)\n",
    "    return vectorizer, features \n",
    "\n",
    "def display_features(features, feature_names):\n",
    "    df = pd.DataFrame(data=features, columns=feature_names)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer, tfidf_X_features = tfidf_extractor(X_train, 10, 'utf-8', (1,2))   # min-df is set to 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<25222x4971 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 340290 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_X_features  # Notice that the number of features is 4971 if min-df is set to 10. As you reduce the value of min-df, the # of features increases so also is RAM consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = tfidf_vectorizer.get_feature_names()\n",
    "X_train_df = display_features(tfidf_X_features.todense(), feature_names)\n",
    "X_train = X_train_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_test_features = tfidf_vectorizer.transform(X_test)\n",
    "X_test_df = display_features(tfidf_test_features.todense(), feature_names)\n",
    "X_test = X_test_df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=10, random_state=26, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Logistic Regression (liblinear) *****\n",
      "Class 0 - Precision: 0.871, Recall: 0.840, F1: 0.855\n",
      "Class 1 - Precision: 0.846, Recall: 0.876, F1: 0.860\n",
      "\n",
      "\n",
      "***** Logistic Regression (lbfgs) *****\n",
      "Class 0 - Precision: 0.871, Recall: 0.840, F1: 0.855\n",
      "Class 1 - Precision: 0.846, Recall: 0.876, F1: 0.860\n",
      "\n",
      "\n",
      "***** Random Forest *****\n",
      "Class 0 - Precision: 0.884, Recall: 0.850, F1: 0.867\n",
      "Class 1 - Precision: 0.856, Recall: 0.889, F1: 0.872\n",
      "\n",
      "\n",
      "***** GaussianNB *****\n",
      "Class 0 - Precision: 0.892, Recall: 0.676, F1: 0.769\n",
      "Class 1 - Precision: 0.739, Recall: 0.919, F1: 0.819\n",
      "\n",
      "\n",
      "***** MultinomialNB *****\n",
      "Class 0 - Precision: 0.882, Recall: 0.821, F1: 0.851\n",
      "Class 1 - Precision: 0.833, Recall: 0.891, F1: 0.861\n",
      "\n",
      "\n",
      "***** SGDClassifier *****\n",
      "Class 0 - Precision: 0.886, Recall: 0.827, F1: 0.855\n",
      "Class 1 - Precision: 0.838, Recall: 0.893, F1: 0.865\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "\n",
    "# Assuming X_train, y_train, and cv are already defined\n",
    "classifiers = [\n",
    "    ('Logistic Regression (liblinear)', LogisticRegression(solver='liblinear', max_iter=1000, random_state=45)),\n",
    "    ('Logistic Regression (lbfgs)', LogisticRegression(solver='lbfgs', max_iter=1000, random_state=45)),\n",
    "    ('Random Forest', RandomForestClassifier(random_state=45)),\n",
    "    ('GaussianNB', GaussianNB()),\n",
    "    ('MultinomialNB', MultinomialNB()),\n",
    "    ('SGDClassifier', SGDClassifier(random_state=45))\n",
    "]\n",
    "\n",
    "# Loop through each classifier\n",
    "for name, model in classifiers:\n",
    "    print('*****', name, '*****')\n",
    "    \n",
    "    # Get the predicted labels using cross_val_predict\n",
    "    y_pred = cross_val_predict(model, X=X_train, y=y_train, cv=cv)\n",
    "    \n",
    "    # Calculate precision, recall, and F1 score for both classes\n",
    "    precision_0 = precision_score(y_train, y_pred, pos_label=0)\n",
    "    recall_0 = recall_score(y_train, y_pred, pos_label=0)\n",
    "    f1_0 = f1_score(y_train, y_pred, pos_label=0)\n",
    "    \n",
    "    precision_1 = precision_score(y_train, y_pred, pos_label=1)\n",
    "    recall_1 = recall_score(y_train, y_pred, pos_label=1)\n",
    "    f1_1 = f1_score(y_train, y_pred, pos_label=1)\n",
    "    for score in [\"roc_auc\", \"f1\", \"precision\", \"recall\", \"accuracy\"]:\n",
    "        cvs = cross_val_score(model, X=X_train, y=y_train, scoring=score, cv=cv).mean()\n",
    "        print(score + \" : \"+ str(cvs))\n",
    "    # Print metrics\n",
    "    print(f'Class 0 - Precision: {precision_0:.3f}, Recall: {recall_0:.3f}, F1: {f1_0:.3f}')\n",
    "    print(f'Class 1 - Precision: {precision_1:.3f}, Recall: {recall_1:.3f}, F1: {f1_1:.3f}')\n",
    "    \n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
